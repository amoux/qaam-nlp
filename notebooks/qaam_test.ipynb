{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from qaam_nlp import QAAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qaam = QAAM(model='en_core_web_sm')\n",
    "qaam.add_url(\"http://25665f7a.ngrok.io\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'deployment',\n",
       " 'context': 'I didn’t understand what was involved in deployment. This was the most frustrating point for me.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLOG_URL = (\"https://www.freecodecamp.org/news/lessons-learned-\"\n",
    "            \"from-deploying-my-first-full-stack-web-application-34f94ec0a286/\")\n",
    "\n",
    "# extract all the texts from the url.\n",
    "qaam.texts_from_url(BLOG_URL)\n",
    "# now we can query questions related to the context.\n",
    "qaam.answer(\"What was the hardest lesson learned?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Backend', 7),\n",
       " ('Frontend', 6),\n",
       " ('two', 5),\n",
       " ('Nginx', 4),\n",
       " ('JavaScript', 4),\n",
       " ('first', 3),\n",
       " ('one', 3),\n",
       " ('Google', 2),\n",
       " ('Amazon', 2),\n",
       " ('thousands', 2)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_blog_entities(spacy_doc: object, top_k=10):\n",
    "    entities = dict()\n",
    "    for ent in doc.ents:\n",
    "        ent = ent.text\n",
    "        if ent not in entities:\n",
    "            entities[ent] = 1\n",
    "        else:\n",
    "            entities[ent] += 1\n",
    "    return Counter(entities).most_common(top_k)\n",
    "\n",
    "get_blog_entities(qaam.doc, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 0.9),\n",
       " ('in', 0.9),\n",
       " ('the', 0.9),\n",
       " ('for', 0.9),\n",
       " ('involved', 0.8),\n",
       " ('most', 0.8),\n",
       " ('me.', 0.8),\n",
       " ('didn’t', 0.7),\n",
       " ('understand', 0.7),\n",
       " ('point', 0.6),\n",
       " ('deployment.', 0.09090909090909094)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from similarity.metric_lcs import MetricLCS\n",
    "\n",
    "def compute_distance(target: str, tokens: List[str], distance_threshold: float = 0.4):\n",
    "    metric_lcs = MetricLCS()\n",
    "    matches = []\n",
    "    similar = {}\n",
    "    for word in tokens:\n",
    "        dist = metric_lcs.distance(target, word)\n",
    "        # lower values -> the closer in distance.\n",
    "        if dist <= distance_threshold:\n",
    "            similar[word] = dist\n",
    "    return similar\n",
    "\n",
    "# Load the question to get the context from the max model.\n",
    "question = \"What was the hardest lesson learned?\"\n",
    "prediction = qaam.answer(question)\n",
    "answer = prediction['answer']\n",
    "context = prediction['context']\n",
    "\n",
    "# Higher thereshold to see the distance metric given to each token.\n",
    "distance = compute_distance(answer, context.split(), 0.9)\n",
    "\n",
    "# Sorted from highest to lowest. \n",
    "sorted(distance.items(), key=lambda i: i[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Instead of using sklearn and TFIDF I could instead use bert for similary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"via spaCy's standard nlp\", 'context': \"Support is provided for fine-tuning the transformer models via spaCy's standard nlp.update training API.\"}\n"
     ]
    }
   ],
   "source": [
    "qaam = QAAM(model='en_trf_bertbaseuncased_lg')\n",
    "qaam.add_url(\"http://25665f7a.ngrok.io\")\n",
    "\n",
    "blog_url = \"https://explosion.ai/blog/spacy-transformers\"\n",
    "question = \"How can I fine tune a transformer model for my task?\"\n",
    "# print out the default similarity metric used by the QAAM class.\n",
    "qaam.texts_from_url(blog_url)\n",
    "predicted_answer = qaam.answer(question)\n",
    "print(predicted_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentencizer', 'trf_wordpiecer', 'trf_tok2vec']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qaam.nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7558835699095946"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity metric from the question to the whole transformers document.\n",
    "qaam.doc.similarity(qaam.nlp(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6286082380288756"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hmm this is too high and not related to the context..\n",
    "qaam.doc.similarity(qaam.nlp(\"How can I know if the sky is blue in my area?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(qaam.nlp.vocab)\n",
    "matcher.add(\"CODE\", None, qaam.nlp(\"nlp.update\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8672180710615960695, 14, 15)]\n"
     ]
    }
   ],
   "source": [
    "context_doc = qaam.nlp(predicted_answer['context'])\n",
    "doc_matches = matcher(context_doc)\n",
    "# (matcher_id, start, end)\n",
    "print(doc_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nlp.update"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PhraseMatcher is also available as a batch pipe.\n",
    "matcher_id, start, end = doc_matches[0]\n",
    "context_doc[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PhraseMatcher.remove\n",
    "\n",
    "> To remove a rule from the matcher by match ID - read the following documentation [removing matcher rules](https://spacy.io/api/phrasematcher#remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking whether the matcher contains rules for a match ID\n",
    "\"CODE\" in matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One important detail is that BERT uses wordpieces (e.g. playing -> play + ##ing)instead of words. This is effective in reducing the size of the vocabulary and increases the amount of data that is available for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'support', 'is', 'provided', 'for', 'fine', '-', 'tuning', 'the', 'transform', '##er', 'models', 'via', 'spa', '##cy', \"'\", 's', 'standard', 'nl', '##p', '.', 'update', 'training', 'api', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(context_doc._.trf_word_pieces_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "import numpy\n",
    "import numpy as np\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between _question and _context is: 0.6397733092308044\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This is the same as -> qaam.doc.similarity(qaam.nlp(doc))\n",
    "_question = qaam.nlp(question)\n",
    "_context = qaam.nlp(predicted_answer['context'])\n",
    "a1_embedding = cupy.asnumpy(_question.tensor.sum(axis=0))\n",
    "a2_embedding = cupy.asnumpy(_context.tensor.sum(axis=0))\n",
    "\n",
    "# similarity is defined as 1 - cosine distance between to arrays\n",
    "cosine_similarity = (1 - distance.cosine(a1_embedding, a2_embedding))\n",
    "print(f'similarity between _question and _context is: {cosine_similarity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sequence(sequence: str):\n",
    "    tensor = qaam.nlp(sequence).tensor.sum(axis=0)\n",
    "    embedd = cupy.asnumpy(tensor)\n",
    "    return embedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8727603554725647"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1 = embed_sequence(\"Transformer models to improve NLP tasks\")\n",
    "embed2 = embed_sequence(\"How transformer models work with textual data\")\n",
    "cossim = 1 - distance.cosine(embed1, embed2)\n",
    "cossim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
